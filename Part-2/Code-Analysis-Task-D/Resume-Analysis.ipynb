{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function will be used to generate the relative path for the _md_ file. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. The line `from collection import Counter` imports the `Counter` function from the `collection` module within importing the full module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os.path.join` function is used to generate the relative path for the _md_ file.\n",
    "\n",
    "Two (2) sets are then defined to store keywords.  The first set, REQUIRED_SKILLS, is used to store strings denoting required skills; the second set, DESIRED_SKILLS, is used to store strings denoting desired skills.  Uppercase is used for all characters of the set names as both sets represent constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a function that reads the _md_ file and performs certain operations to the read data.\n",
    "\n",
    "The `with` function is used in conjunction with the `open` function in order to ensure that the file is closed after all desired operations are performed.  All functions identified below `with` and `open` and indented are performed while the file is open.\n",
    "\n",
    "The parameters _filepath_ and _\"r\"_ indicate, respectively, the location of the file as well as the operation to be performed, which in this case is read.  The _md_ file is opened as _resume_file_handler_.  The `read` function is used to read the information in _resume_file_handler,_ and the data is then stored in _resume_contents_.  The following line converts all characters in _resume_contents_ to lowercase and reassigns _resume_contents_ to store this reformatted data.  Following this, the `split` function is used to split the data contained in _resume_contents_ using the default delimiter (i.e., space).  The resulting data is then stored in _resume_tokens_.  After the preceding operations are performed, the modified data (i.e., _resume_tokens)_ is returned.  _resume_tokens_ yields a list of words or character groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below uses the `load_file` function defined above to process the information in the _md_ file represented by the relative path location _resume_path_.\n",
    "\n",
    "The list of words or character groupings that results from using the `load_file` function is stored in _word_list_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, _resume_ is declared as a set; _resume_ is later used to store all unique words/character groupings contained in _word_list_.  \n",
    "\n",
    "The set _resume_ is populated using a `for` loop and the `add` function.  The `for` loop iterates through each entry of _word_list_.  Because sets do not allow for multiple entries of the same value, the `add` function will only add unique entries from _world_list_ to _resume_.\n",
    "\n",
    "The next 2 lines are used to identify and print the values contained in the set _resume_.  In the first `print` line, the escape character `\\n` is used to create a new line, resulting in an empty line to be printed followed by the string 'WORDS BEFORE MOVING PUNCTUATION' in the line directly below.\n",
    "\n",
    "Another set, _punctuation,_ is declared to store punctuations.  This set is populated using the `punctuation` function of the `string` module.  This set is then subtracted from _resume_ to remove punctuations that were read and stored as separate entries in _resume_.  The set _resume_ is reassigned to store this reduced set.  Punctuations are not words, and thus should be removed from _resume_ to produce a more accurate accounting of actual words contained in the _md_ file.\n",
    "\n",
    "The last 2 lines are used to identify and print the values contained in the updated _resume_ set.  In the first `print` line, the escape character `\\n` is again used to create a new line, resulting in an empty line to be printed followed by the string 'WORDS AFTER MOVING PUNCTUATION' in the line directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'microsoft', 'graduate', 'mining', 'writing', 'files', 'excel,', 'hadoop', 'sql,', 'experience', 'git/github', 'intelligence', 'r,', 'analyze', 'learning,', '##', 'html/css,', 'learning', 'd3,', 'algorithms', 'html,', 'performing', 'apis.', 'mysql', 'python', 'visualization', 'python,', 'excel.', 'education', 'interests', 'with', 'interactions,', 'leaflet.js', 'data', 'working', 'forecasting', 'business', 'tableau,', 'creating', 'scripts', 'css,', 'databases', 'contributing', 'javascript,', 'statistics', 'api', 'from', 'pivot', 'tables', 'dartling', 'hadoop,', 'modeling', 'front-end', 'aws', 'dartanion', 'the', 'big', 'analytics', 'bootstrap,', 'machine', 'boot', 'mongodb', 'basic', 'designing', 'skills', 'apps', 'software', 'using', 'to', 'tableau', 'cloud', 'sets', 'developing', '#', 'web', 'd.', 'vba', 'mining,', 'd3', 'social', 'advanced', 'pandas', 'media', 'statistics,', 'and', 'camp', 'visualizations', 'in', 'open-source', '*'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'microsoft', 'graduate', 'mining', 'writing', 'files', 'excel,', 'hadoop', 'sql,', 'experience', 'git/github', 'intelligence', 'r,', 'analyze', 'learning,', '##', 'html/css,', 'learning', 'd3,', 'algorithms', 'html,', 'performing', 'apis.', 'mysql', 'python', 'visualization', 'python,', 'excel.', 'education', 'interests', 'with', 'interactions,', 'leaflet.js', 'data', 'working', 'forecasting', 'business', 'tableau,', 'creating', 'scripts', 'css,', 'databases', 'contributing', 'javascript,', 'statistics', 'api', 'from', 'pivot', 'tables', 'dartling', 'hadoop,', 'modeling', 'front-end', 'aws', 'dartanion', 'the', 'big', 'analytics', 'bootstrap,', 'machine', 'boot', 'mongodb', 'basic', 'designing', 'skills', 'apps', 'software', 'using', 'to', 'tableau', 'cloud', 'sets', 'developing', 'web', 'd.', 'vba', 'mining,', 'd3', 'social', 'advanced', 'pandas', 'media', 'statistics,', 'and', 'camp', 'visualizations', 'in', 'open-source'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the cell below prints the string 'REQUIRED SKILLS' followed by the values _resume_ and _REQUIRED_SKILLS_ have in common.  The values the 2 sets have in common are identified using the `intersection` function, which here is denoted by the ampersand.\n",
    "\n",
    "The next set of print commands performs a similar operation.  In this instance the string 'DESIRED SKILLS' is printed followed by the values _resume_ and _DESIRED_SKILLS_ have in common.  Again, the values the 2 sets have in common are identified using the `intersection` function, which is denoted by the ampersand.\n",
    "\n",
    "The following lines are used to clean the data contained in _word_list_. Punctuations and stop words are removed using list comprehension.\n",
    "\n",
    "Punctuations are removed in 2 steps.  The first removes punctuations that were read and stored in _word_list_ as separate entries.  The second removes punctuations that were read and stored as part of words (e.g., periods ending sentences).  \n",
    "\n",
    "For the former, a `for` loop is used to iterate through each entry in _word_list_.  A conditional is then used to determine whether or not an entry is punctuation.  An entry is retained if it cannot be found in `string.punctuation`; otherwise, the entry is dropped.  _word_list_ is reassigned to store the retained entries.\n",
    "\n",
    "For the latter, a `for` loop is also used to iterate through each entry in _word_list_.  However, another `for` loop is then used to iterate through each character in each entry in _word_list_.  Within the second `for` loop, a conditional is used to determine which characters of the entry are kept.  Characters that are punctuations (i.e., characters found in `string.punctuation`) are ignored; only non-punctuation characters are retained.  The `join` function is used to concatenate the retained characters and create the new entries.  _word_list_ is again reassigned to store these new entries.\n",
    "\n",
    "To remove stop words from _word_list,_ a list contraining stop words are first defined.  A `for` loop is used to iterate through each entry in _word_list_.  A conditional is then used to determine whether or not an entry is a stop word.  An entry is retained if it does not match any of the words contained in _word_list;_ otherwise, the entry is dropped.  Once more, _word_list_ is reassigned to store the retained entries.\n",
    "\n",
    "The retained entries are printed after each cleaning step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'mysql', 'python', 'statistics'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['dartanion', 'd.', 'dartling', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['dartanion', 'd', 'dartling', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['dartanion', 'd', 'dartling', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below provides two means of determining the frequency by which each word in the _md_ file is used.  \n",
    "\n",
    "In the first method, _word_counter_ is declared as a dictionary.  Using the `fromkeys` function, unique entries from _word_list_ are used as the keys for _word_counter,_ with each key assigned a corresponding value. The corresponding value is set as 0 initially as it will be used as the counter.  A `for` loop is then used to iterate through each entry in _word_list_.  Each entry is compared to the keys in _word_counter_.  If the entry matches a key, 1 is added to the corresponding value of the key.  Once the iteration is complete, _word_counter_ should provide the number of times each word/key matched an entry in _word_list_. \n",
    "\n",
    "In the second method, the function `Counter` from the `collections` class is used to determine the number of times a word is used. Similar to the first method, the `Counter` function also iterates through the entries in _word_list_ and uses a dictionary to track and count the occurence of each word.  Unlike the first method, the `Counter` function is predefined.\n",
    "\n",
    "The results of the 2 methods are then compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the `sorted` function is used to re-organize _word_count_ based on the corresponding values of each key in descending order.  Specifically, the key with the highest corresponding value will be assigned index zero.  The key with the lowest corresponding value, on the other hand, will be assigned the highest index number/location.\n",
    "\n",
    "The \"iterable\" parameter of the `sorted` function identifies the dictionary to be sorted; lists, etc. can also be specified.  The \"key\" parameter, on the other hand, specifies the information that will be used as the basis for sorting; in this instance, the values corresponding to each key is used.  The `get` function is used to retrieve the value corresponding to each key.  In order to specify the order as descending rather than ascending, the \"reverse\" parameter is set to \"True\".  \n",
    "\n",
    "A `for` loop is used to print the top ten entries in the sorted dictionary; `[:10]` is used to specify the index range to be printed.  Therefore, indexes 0 through 9 will be printed.\n",
    "\n",
    "One way to remove the blank token is by using the `drop` function.  The following script can be inserted and executed prior to the `for` loop in the cell below: _word_count.pop('', None)_.\n",
    "\n",
    "Note: _sorted_words_ does not need to be declared as it serves no puropse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "\n",
    "#word_count.pop('', None)\n",
    "\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
